{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fec835",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f6d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_id': 89879, 'drugName': 'Cyclosporine', 'condition': 'keratoconjunctivitis sicca', 'review': '\"I have used Restasis for about a year now and have seen almost no progress.  For most of my life I\\'ve had red and bothersome eyes. After trying various eye drops, my doctor recommended Restasis.  He said it typically takes 3 to 6 months for it to really kick in but it never did kick in.  When I put the drops in it burns my eyes for the first 30 - 40 minutes.  I\\'ve talked with my doctor about this and he said it is normal but should go away after some time, but it hasn\\'t. Every year around spring time my eyes get terrible irritated  and this year has been the same (maybe even worse than other years) even though I\\'ve been using Restasis for a year now. The only difference I notice was for the first couple weeks, but now I\\'m ready to move on.\"', 'rating': 2.0, 'date': 'April 20, 2013', 'usefulCount': 69, 'review_length': 147}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "data_files = {\n",
    "    \"train\": \"drug-reviews-train.jsonl\",\n",
    "    \"validation\": \"drug-reviews-validation.jsonl\",\n",
    "    \"test\": \"drug-reviews-test.jsonl\",\n",
    "}\n",
    "drug_dataset_reloaded = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# View one example\n",
    "print(drug_dataset_reloaded['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3baac0a",
   "metadata": {},
   "source": [
    "### Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4d0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_id': 89879, 'drugName': 'Cyclosporine', 'condition': 'keratoconjunctivitis sicca', 'review': '\"I have used Restasis for about a year now and have seen almost no progress.  For most of my life I\\'ve had red and bothersome eyes. After trying various eye drops, my doctor recommended Restasis.  He said it typically takes 3 to 6 months for it to really kick in but it never did kick in.  When I put the drops in it burns my eyes for the first 30 - 40 minutes.  I\\'ve talked with my doctor about this and he said it is normal but should go away after some time, but it hasn\\'t. Every year around spring time my eyes get terrible irritated  and this year has been the same (maybe even worse than other years) even though I\\'ve been using Restasis for a year now. The only difference I notice was for the first couple weeks, but now I\\'m ready to move on.\"', 'rating': 2.0, 'date': 'April 20, 2013', 'usefulCount': 69, 'review_length': 147, 'label': 425}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get all unique conditions from the train set\n",
    "conditions = list(set(example['condition'] for example in drug_dataset_reloaded['train'] if example['condition']))\n",
    "\n",
    "# Step 2: Create label mappings\n",
    "label2id = {label: idx for idx, label in enumerate(sorted(conditions))}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Step 3: Apply the mapping\n",
    "def encode_labels(example):\n",
    "    example['label'] = label2id.get(example['condition'], -1)  # -1 for unknown/missing\n",
    "    return example\n",
    "\n",
    "# Map to all splits\n",
    "encoded_dataset = drug_dataset_reloaded.map(encode_labels)\n",
    "print(encoded_dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9ef04",
   "metadata": {},
   "source": [
    "### Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ee691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 27703/27703 [00:11<00:00, 2463.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "# Load DistilBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") #using this model is for building your own classifier, like predicting conditions from drug reviews (multiclass classification).\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"review\"], truncation=True, padding=True  )\n",
    "\n",
    "# Apply tokenization to all splits\n",
    "tokenized_dataset = encoded_dataset.map(tokenize, batched=True)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(\n",
    "    [col for col in drug_dataset_reloaded[\"train\"].column_names if col not in [\"review\", \"condition\", \"label\"]]\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aed5868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition': 'keratoconjunctivitis sicca', 'review': '\"I have used Restasis for about a year now and have seen almost no progress.  For most of my life I\\'ve had red and bothersome eyes. After trying various eye drops, my doctor recommended Restasis.  He said it typically takes 3 to 6 months for it to really kick in but it never did kick in.  When I put the drops in it burns my eyes for the first 30 - 40 minutes.  I\\'ve talked with my doctor about this and he said it is normal but should go away after some time, but it hasn\\'t. Every year around spring time my eyes get terrible irritated  and this year has been the same (maybe even worse than other years) even though I\\'ve been using Restasis for a year now. The only difference I notice was for the first couple weeks, but now I\\'m ready to move on.\"', 'label': 425, 'input_ids': [101, 1000, 1045, 2031, 2109, 2717, 21369, 2015, 2005, 2055, 1037, 2095, 2085, 1998, 2031, 2464, 2471, 2053, 5082, 1012, 2005, 2087, 1997, 2026, 2166, 1045, 1005, 2310, 2018, 2417, 1998, 8572, 14045, 2159, 1012, 2044, 2667, 2536, 3239, 9010, 1010, 2026, 3460, 6749, 2717, 21369, 2015, 1012, 2002, 2056, 2009, 4050, 3138, 1017, 2000, 1020, 2706, 2005, 2009, 2000, 2428, 5926, 1999, 2021, 2009, 2196, 2106, 5926, 1999, 1012, 2043, 1045, 2404, 1996, 9010, 1999, 2009, 7641, 2026, 2159, 2005, 1996, 2034, 2382, 1011, 2871, 2781, 1012, 1045, 1005, 2310, 5720, 2007, 2026, 3460, 2055, 2023, 1998, 2002, 2056, 2009, 2003, 3671, 2021, 2323, 2175, 2185, 2044, 2070, 2051, 1010, 2021, 2009, 8440, 1005, 1056, 1012, 2296, 2095, 2105, 3500, 2051, 2026, 2159, 2131, 6659, 15560, 1998, 2023, 2095, 2038, 2042, 1996, 2168, 1006, 2672, 2130, 4788, 2084, 2060, 2086, 1007, 2130, 2295, 1045, 1005, 2310, 2042, 2478, 2717, 21369, 2015, 2005, 1037, 2095, 2085, 1012, 1996, 2069, 4489, 1045, 5060, 2001, 2005, 1996, 2034, 3232, 3134, 1010, 2021, 2085, 1045, 1005, 1049, 3201, 2000, 2693, 2006, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805f8fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['condition', 'review', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 110811\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2574352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = tokenized_dataset.remove_columns( ['patient_id', 'drugName', 'rating', 'date', 'usefulCount', 'review_length','condition', 'review'])\n",
    "tokenized_dataset = tokenized_dataset.remove_columns( ['condition', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1af16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b07642",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "513bc7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2364b445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attention_mask', 'input_ids', 'labels']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"attention_mask\", \"input_ids\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa12c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3183600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8]),\n",
       " 'input_ids': torch.Size([8, 512]),\n",
       " 'attention_mask': torch.Size([8, 512])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013f344",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1fdc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (2.7.0+cu128)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c9bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/41556 [20:40<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "accelerator = Accelerator()\n",
    "print(\"Using device:\", accelerator.device)\n",
    "\n",
    "# How many classes?\n",
    "num_labels = len(label2id)\n",
    "\n",
    "# Load the model with correct output size\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
    "    train_dataloader, eval_dataloader, model, optimizer\n",
    ")\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dl)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37da006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  7 12:46:18 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   62C    P8            N/A  / 5001W |    3517MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            8716      C   ...onda3\\envs\\pytorch\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2e0897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device name:NVIDIA GeForce GTX 1050 Ti\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=791, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"device name:\"+torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d574abf",
   "metadata": {},
   "source": [
    "### Setup Evaluation Computing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "960bf362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca0e86",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d981a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f483812",
   "metadata": {},
   "source": [
    "### Create a Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "137a847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8716\\1293148538.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc5a7a",
   "metadata": {},
   "source": [
    "### Train then Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41556 [05:12<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1709' max='20778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1709/20778 2:07:55 < 23:48:59, 0.22 it/s, Epoch 0.25/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "trainer.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dl:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5882b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
